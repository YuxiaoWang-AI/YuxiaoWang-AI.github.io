---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently a Ph.D. candidate at the School of Future Technology, South China University of Technology (SCUT), under the supervision of Prof. Qi Liu. I conduct my research in the Multimodal Computing and Interaction (MCI) Laboratory, focusing on multimodal learning and artificial intelligence, with specific interests in Human-Object Interaction (HOI) detection, Vision-Language Models (VLMs), and crowd counting.

With over 10 years of programming experience, I have developed strong engineering capabilities. I am proficient in deep learning frameworks such as PyTorch and experienced with database technologies including MongoDB and S3. I have published more than 10 academic papers in prestigious venues, including top-tier SCI journals such as IEEE TCSVT, TNNLS, and Neural Networks, as well as CCF A-ranked conferences including ICCV and AAAI.

Throughout my academic career, I have been honored with the National Scholarship and the Presidential Scholarship of SCUT on multiple occasions. I have also actively participated in various competitions, receiving awards such as the First Prize in the Lanqiao Cup Programming Contest (Hebei Province), the National First Prize in the Mathorcup Big Data Competition (Graduate Division), and the National First Prize in the China Collegiate Big Data Challenge (Graduate Division).

æˆ‘ç›®å‰æ˜¯åå—ç†å·¥å¤§å­¦æœªæ¥æŠ€æœ¯å­¦é™¢çš„åšå£«ç ”ç©¶ç”Ÿï¼Œå¸ˆä»åˆ˜ç¦æ•™æˆï¼Œåœ¨å¤šæ¨¡æ€è®¡ç®—ä¸äº¤äº’ï¼ˆMCIï¼‰å®éªŒå®¤ä»äº‹ç ”ç©¶å·¥ä½œã€‚æˆ‘çš„ç ”ç©¶æ–¹å‘èšç„¦äºå¤šæ¨¡æ€å­¦ä¹ ä¸äººå·¥æ™ºèƒ½ï¼Œå…·ä½“åŒ…æ‹¬äºº-ç‰©äº¤äº’æ£€æµ‹ã€è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰åŠäººç¾¤è®¡æ•°ç­‰ã€‚æˆ‘æ‹¥æœ‰10å¹´ç¼–ç¨‹ç»éªŒï¼Œå…·å¤‡æ‰å®çš„å·¥ç¨‹å¼€å‘èƒ½åŠ›ï¼Œèƒ½å¤Ÿç†Ÿç»ƒè¿ç”¨ PyTorch ç­‰æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå¹¶æŒæ¡ MongoDBã€S3 ç­‰æ•°æ®å­˜å‚¨æŠ€æœ¯ã€‚åœ¨å­¦æœ¯æ–¹é¢ï¼Œæˆ‘å·²å…¬å¼€å‘è¡¨è®ºæ–‡10ä½™ç¯‡ï¼Œæˆæœå‘è¡¨äº IEEE TCSVTã€TNNLSã€Neural Networks ç­‰ SCI ä¸€åŒº Top æœŸåˆŠï¼Œä»¥åŠ ICCVã€AAAI ç­‰ CCF A ç±»é¡¶çº§ä¼šè®®ã€‚
åœ¨æ ¡æœŸé—´ï¼Œæˆ‘æ›¾å¤šæ¬¡è£è·å›½å®¶å¥–å­¦é‡‘ã€åå—ç†å·¥å¤§å­¦æ ¡é•¿å¥–å­¦é‡‘ç­‰è£èª‰ã€‚æ­¤å¤–ï¼Œæˆ‘ç§¯æå‚ä¸å„ç±»å­¦ç§‘ç«èµ›ï¼Œæ›¾è·æ²³åŒ—çœè“æ¡¥æ¯ç¨‹åºè®¾è®¡å¤§èµ›ä¸€ç­‰å¥–ã€Mathorcup é«˜æ ¡æ•°å­¦å»ºæ¨¡æŒ‘æˆ˜èµ›å¤§æ•°æ®ç«èµ›ç ”ç©¶ç”Ÿç»„å…¨å›½ä¸€ç­‰å¥–ã€ä¸­å›½é«˜æ ¡å¤§æ•°æ®æŒ‘æˆ˜èµ›ç ”ç©¶ç”Ÿç»„å…¨å›½ä¸€ç­‰å¥–ç­‰å¥–é¡¹ã€‚

<!--
My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).
-->



# ğŸ”¥ News
- *2026.01*: &nbsp;ğŸ‰ğŸ‰ Congratulations! One papers have been accepted by <strong style="color: red;">ICASSP 2026 (CCF B)</strong>!
- *2025.11*: &nbsp;ğŸ™‹ğŸ™‹ Congratulations! Selected as a volunteer for <strong style="color: red;">AAAI 2026</strong>!
- *2025.11*: &nbsp;ğŸ‰ğŸ‰ Congratulations! Two papers have been accepted by <strong style="color: red;">AAAI 2026 (CCF A)</strong>!
- *2025.06*: &nbsp;ğŸ‰ğŸ‰ Congratulations! One paper on Human-Object Contact Detection has been accepted by <strong style="color: red;">ICCV 2025 (CCF A)</strong>!
- *2025.02*: &nbsp;ğŸŠğŸŠ Congratulations! Served as Workshop Chair for <strong style="color: red;">ICIVIS 2025</strong>!
- *2024.12*: &nbsp;ğŸ‰ğŸ‰ Congratulations! One paper on Human-Object Contact Detection has been accepted by <strong style="color: red;">AAAI 2025 as <strong style="color: purple;">Oral</strong> presentation (CCF A)</strong>!
- *2024.12*: &nbsp;ğŸ‰ğŸ‰ Congratulations! One paper have been accepted by <strong style="color: red;">AAAI 2025 (CCF A)</strong>!
- *2024.10*: &nbsp;ğŸ†ğŸ† Congratulations! Awarded <strong style="color: red;">National Scholarship</strong> and <strong style="color: red;">SCUT Presidential Scholarship</strong>!
- *2024.08*: &nbsp;ğŸ‰ğŸ‰ Congratulations! One paper has been selected as Best Paper Award at <strong style="color: red;">ICCBD+AI 2024</strong>!
- *2024.08*: &nbsp;ğŸ‰ğŸ‰ Congratulations! One paper has been selected as Best Paper Award at <strong style="color: red;">ICCVIT 2024</strong>!
- *2024.03*: &nbsp;ğŸ‰ğŸ‰ Congratulations! One paper "TED-Net" has been accepted by <strong style="color: red;">IEEE TCSVT (SCI Q1 Top)</strong>!
- *2023.10*: &nbsp;ğŸ†ğŸ† Congratulations! Awarded <strong style="color: red;">SCUT Presidential Scholarship</strong>!
- *2022.10*: &nbsp;ğŸ†ğŸ† Congratulations! Awarded <strong style="color: red;">SCUT Presidential Scholarship</strong>!
- *2022.09*: &nbsp;ğŸ“ğŸ“ Started my Ph.D. journey at the School of Future Technology, South China University of Technology!
- *2022.06*: &nbsp;ğŸ‰ğŸ‰ Congratulations! Successfully obtained my Master's degree from Hebei University!
- *2021.07*: &nbsp;ğŸ‰ğŸ‰ Congratulations! One paper has been accepted by <strong style="color: red;">Applied Intelligence (JCR Q1)</strong>!

# ğŸ“ Publications 

<!-- AAAI 2026 - What-Meets-Where -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2026</div><img src='images/PaIR.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[What-Meets-Where: Unified Learning of Action and Contact Localization in Images](https://arxiv.org/pdf/2508.09428)

**Yuxiao Wang**, Yi Lei, Wenlu Liang, Wentao Xue, Zhen Wei, Nan Zhuang, Qiang Liu*

[**Paper**](https://arxiv.org/pdf/2508.09428) | [**Code**](https://github.com/YuxiaoWang-AI/PaIR)
-  we present PaIR (Partaware Interaction Representation) **dataset**, a comprehensive dataset
containing 13,979 images that encompass 654 actions, 80 object categories, and 17 body parts.
- We present a unified framework for jointly learning action recognition and contact localization in images.
</div>
</div>

<!-- AAAI 2026 - QueryCraft -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2026</div><img src='images/QueryCraft.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[QueryCraft: Transformer-Guided Query Initialization for Enhanced Human-Object Interaction Detection](https://arxiv.org/pdf/2508.08590)

**Yuxiao Wangâ€ **, Wenlu Liangâ€ , Yi Lei, Wentao Xue, Nan Zhuang, Qiang Liu*

[**Paper**](https://arxiv.org/pdf/2508.08590) | [**Code**](https://github.com/YuxiaoWang-AI/QueryCraft)
- We propose QueryCraft, a transformer-guided query initialization method for enhanced human-object interaction detection.
</div>
</div>

<!-- ICCV 2025 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2025</div><img src='images/P3HOT.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Prompt Guidance and Human Proximal Perception for HOT Prediction with Regional Joint Loss](https://arxiv.org/pdf/2507.01630)

**Yuxiao Wang**, Yi Lei, Zhen Wei, Wentao Xue, Nan Zhuang, Qiang Liu*

[**Paper**](https://arxiv.org/pdf/2507.01630) | [**Code**](https://github.com/YuxiaoWang-AI/P3HOT)
- We introduce prompt guidance and human proximal perception for human-object contact prediction, significantly improving detection accuracy.
</div>
</div>

<!-- AAAI 2025 Oral -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2025 <strong style="color: red;">Oral</strong></div><img src='images/PIHOT.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Precision-Enhanced Human-Object Contact Detection via Depth-Aware Perspective Interaction and Object Texture Restoration](https://ojs.aaai.org/index.php/AAAI/article/view/32883)

**Yuxiao Wang**, Wanying Neng, Zhen Wei, Yi Lei, Wentao Xue, Nan Zhuang, Yanwei Xu, Xin Jiang, Qi Liu*

[**Paper**](https://ojs.aaai.org/index.php/AAAI/article/view/32883) | [**Code**](https://github.com/YuxiaoWang-AI/PIHOT)
- We propose a depth-aware framework for human-object contact detection, achieving state-of-the-art performance on multiple benchmarks.
</div>
</div>

<!-- AAAI 2025 Oral -->
<!--
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2025 <strong style="color: red;">Oral</strong></div><img src='images/LLM.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[LLM Agents Can Be Choice-Supportive Biased Evaluators: An Empirical Study](https://ojs.aaai.org/index.php/AAAI/article/view/34843)

Nan Zhuang, Boyu Cao, Yi Yang, Jing Xu, Mingda Xu, **Yuxiao Wang**, Qi Liu*

[**Paper**](https://ojs.aaai.org/index.php/AAAI/article/view/34843)
- This study is the first to thoroughly examine the choice-supportive bias in LLM agents, a cognitive bias that is known to impact human decisionmaking and evaluation.
</div>
</div>
-->

<!-- ICCVIT 2024 - Review -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCVIT 2024</div><img src='images/HOI_Review.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[A Review of Human-Object Interaction Detection](https://arxiv.org/pdf/2408.10641)

**Yuxiao Wang**, Yi Lei, Linbo Cui, Wentao Xue, Qiang Liu, Zhen Wei*

[**Paper**](https://arxiv.org/pdf/2408.10641)
- We provide a comprehensive review of human-object interaction detection methods, covering datasets, evaluation metrics, and future directions.
</div>
</div>

<!-- ICCBD+AI 2024 Best Paper -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCBD+AI 2024 Best Paper</div><img src='images/DeHOT.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DeHOT: Reconstructing Pseudo-3D Scenes for Human-Object Contact Detection](https://drliuqi.github.io/files/publications/DeHOT.pdf)

**Yuxiao Wang**, Yi Lei, Qianxi Xiong, Wentao Xue, Qiang Liu, Zhen Wei*

ğŸ† **Best Paper Award**

[**Paper**](https://drliuqi.github.io/files/publications/DeHOT.pdf)
- We propose DeHOT for reconstructing pseudo-3D scenes to enhance human-object contact detection performance.
</div>
</div>

<!-- IEEE TCSVT -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE TCSVT 2024</div><img src='images/TED-Net.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[TED-Net: Dispersal Attention for Perceiving Interaction Region in Indirectly-Contact HOI Detection](https://ieeexplore.ieee.org/abstract/document/10415065)

**Yuxiao Wang**, Qiang Liu*, Yi Lei

[**Paper**](https://ieeexplore.ieee.org/abstract/document/10415065) | [**Code**](https://github.com/YuxiaoWang-AI/TED-Net)
- We propose TED-Net with dispersal attention mechanism for indirectly-contact human-object interaction detection.
</div>
</div>

<!-- Applied Intelligence -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Applied Intelligence</div><img src='images/Capsule.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[A General Multi-Scale Image Classification Based on Shared Conversion Matrix Routing](https://link.springer.com/article/10.1007/s10489-021-02558-1)

**Yuxiao Wang**, Kang Li*, Yi Lei

Applied Intelligence, 2022, 52(3): 3249-3265. **(SCI Q1)**

[**Paper**](https://link.springer.com/article/10.1007/s10489-021-02558-1)
- We propose a general multi-scale image classification method based on shared conversion matrix routing.
</div>
</div>



<!--
- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**
-->

# ğŸ– Honors and Awards
- *2024.10* National Scholarship (å›½å®¶å¥–å­¦é‡‘)
- *2024.10* Presidential Scholarship of South China University of Technology (åå—ç†å·¥å¤§å­¦æ ¡é•¿å¥–å­¦é‡‘)
- *2023.10* Presidential Scholarship of South China University of Technology (åå—ç†å·¥å¤§å­¦æ ¡é•¿å¥–å­¦é‡‘)
- *2022.10* Presidential Scholarship of South China University of Technology (åå—ç†å·¥å¤§å­¦æ ¡é•¿å¥–å­¦é‡‘)
- *2021.10* National First Prize in Mathorcup Big Data Competition (Graduate Division) (Mathorcupé«˜æ ¡æ•°å­¦å»ºæ¨¡æŒ‘æˆ˜èµ›å¤§æ•°æ®ç«èµ›ç ”ç©¶ç”Ÿç»„å…¨å›½ä¸€ç­‰å¥–)
- *2021.10* National First Prize in China Collegiate Big Data Challenge (Graduate Division) (ä¸­å›½é«˜æ ¡å¤§æ•°æ®æŒ‘æˆ˜èµ›ç ”ç©¶ç”Ÿç»„å…¨å›½ä¸€ç­‰å¥–)
- *2019.06* Outstanding Graduate of Hebei Province (æ²³åŒ—çœé«˜æ ¡ä¼˜ç§€æ¯•ä¸šç”Ÿ)
- *2018.05* First Prize in Lanqiao Cup Programming Contest, Hebei Province (æ²³åŒ—çœè“æ¡¥æ¯å¤§èµ›ä¸€ç­‰å¥–)
- *2017-2018* Provincial Merit Student of Hebei Province (æ²³åŒ—çœçœçº§ä¸‰å¥½å­¦ç”Ÿ)
- *2016-2017* National Scholarship (å›½å®¶å¥–å­¦é‡‘)

# ğŸ“– Educations
- *2022.09 - Present*, Ph.D. in Information and Communication Engineering, School of Future Technology, South China University of Technology, Guangzhou, China.
  - Research Interests: Multimodal Learning, Human-Object Interaction Detection, Human-Object Contact Detection, Vision-Language Models (VLM)
  - Supervisor: Prof. Qiang Liu
- *2019.09 - 2022.06*, M.S. in Computer Technology, School of Cyber Security and Computer, Hebei University, Baoding, China.
  - Research Interests: Computer Vision, Image Classification, Semantic Segmentation

<!--
# ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)
-->

# ğŸ’» Internships
- *2025.11 - Present*, Algorithm Researcher, [Huawei Technologies Co., Ltd.](https://www.huawei.com/) (2012 Lab), Shenzhen, China.
- *2025.07 - 2025.11*, Algorithm Engineer (Tech Lead), [Chuangxin International Biotechnology](https://www.bio-accurate.com/), Guangzhou, China.
- *2024.07 - 2025.02*, Algorithm Engineer, [Caotuli Technology Co., Ltd.](https://intuly.com/), Guangzhou, China.
- *2024.04 - 2024.07*, Algorithm Engineer, [Youmi Zhixing Technology Co., Ltd.](), Guangzhou, China.
- *2021.06 - 2023.09*, Algorithm Intern, [Yibang (Beijing) Intelligent Technology Co., Ltd.](https://www.ebondhm.com/homePage), Beijing, China.
